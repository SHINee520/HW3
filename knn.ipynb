{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split    #分割資料集"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "df = pd.read_csv('movie.csv')\n",
    "df = df.drop(labels=['Unnamed: 0'],axis='columns')\n",
    "\n",
    "def cutval(df):\n",
    "    topcut = []\n",
    "    for d in df['簡介']:\n",
    "        top = jieba.analyse.extract_tags(d,topK=10)\n",
    "        topcut.append(top)\n",
    "\n",
    "    typecut = []\n",
    "    for d in df['類型']:\n",
    "        ch =re.compile(\"[\\u4e00-\\u9fa5]\")\n",
    "        seg_word =  \"\".join(ch.findall(d))\n",
    "        top = jieba.lcut(seg_word)\n",
    "        typecut.append(top)\n",
    "\n",
    "    namecut = []\n",
    "    for d in df['中文名稱']:\n",
    "        ch =re.compile(\"[\\u4e00-\\u9fa5]\")\n",
    "        name =  \"\".join(ch.findall(d))\n",
    "        namecut.append(name)\n",
    "\n",
    "    data = { 'type':typecut ,'name':namecut,'article':topcut}\n",
    "    df1 = pd.DataFrame(data)\n",
    "\n",
    "    df1['type'] = df1['type'].apply(lambda x :  str(x)[1:-2].replace(\"'\",\"\").replace(\",\",\"\"))\n",
    "    df1['article'] = df1['article'].apply(lambda x :  str(x)[1:-2].replace(\"'\",\"\").replace(\",\",\"\"))\n",
    "    df1['key'] = df1['name'].astype(str)+' '+df1['type'].astype(str)+' '+df1['article'].astype(str)\n",
    "    return df1\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def count(df):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(df['key'])\n",
    "    tfidf = TfidfTransformer() \n",
    "    tf=tfidf.fit_transform(X)\n",
    "    word = vectorizer.get_feature_names() #詞袋 \n",
    "    weight=tf.toarray() #轉化成數組的形式 \n",
    "    df3=pd.DataFrame(weight,columns=word)\n",
    "    # print (X)\n",
    "    # return feature_name\n",
    "    # return X.toarray()\n",
    "    return tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def knn(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y['type'].str[0:2], test_size=0.07659)\n",
    "    clf=KNeighborsClassifier(n_neighbors=17)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)    # 預測模型\n",
    "    # accuracy =  str(y_pred) == str(y_test) \n",
    "    print(y_pred)    # 計算精準度\n",
    "    y_test=y_test.values\n",
    "    print(y_test)\n",
    "\n",
    "    # correct = 0\n",
    "    # for i in range(500):\n",
    "    #     if y_pred[i] == y_test[i]:\n",
    "    #         correct +=1 \n",
    "    # accuracy = correct/500\n",
    "    # print(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "df1 = cutval(df) \n",
    "tf = count(df1)\n",
    "knn(tf,df1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}